{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tensorflow_lite",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "e5BPui9TlZut"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tf.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bw3-QUxBliyW",
        "outputId": "30645671-2326-45aa-92a1-bb527ea9f41c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(help(tf.lite.TFLiteConverter))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sih1lFvllrad",
        "outputId": "f8731047-27ae-4a0b-85ba-5a483acc417c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Help on class TFLiteConverterV2 in module tensorflow.lite.python.lite:\n",
            "\n",
            "class TFLiteConverterV2(TFLiteFrozenGraphConverterV2)\n",
            " |  TFLiteConverterV2(funcs, trackable_obj=None)\n",
            " |  \n",
            " |  Converts a TensorFlow model into TensorFlow Lite model.\n",
            " |  \n",
            " |  Attributes:\n",
            " |    optimizations: Experimental flag, subject to change. Set of optimizations to\n",
            " |      apply. e.g {tf.lite.Optimize.DEFAULT}. (default None, must be None or a\n",
            " |      set of values of type `tf.lite.Optimize`)\n",
            " |    representative_dataset: A generator function used for integer quantization\n",
            " |      where each generated sample has the same order, type and shape as the\n",
            " |      inputs to the model. Usually, this is a small subset of a few hundred\n",
            " |      samples randomly chosen, in no particular order, from the training or\n",
            " |      evaluation dataset. This is an optional attribute, but required for full\n",
            " |      integer quantization, i.e, if `tf.int8` is the only supported type in\n",
            " |      `target_spec.supported_types`. Refer to `tf.lite.RepresentativeDataset`.\n",
            " |      (default None)\n",
            " |    target_spec: Experimental flag, subject to change. Specifications of target\n",
            " |      device, including supported ops set, supported types and a set of user's\n",
            " |      defined TensorFlow operators required in the TensorFlow Lite runtime.\n",
            " |      Refer to `tf.lite.TargetSpec`.\n",
            " |    inference_input_type: Data type of the input layer. Note that integer types\n",
            " |      (tf.int8 and tf.uint8) are currently only supported for post training\n",
            " |      integer quantization and quantization aware training. (default tf.float32,\n",
            " |      must be in {tf.float32, tf.int8, tf.uint8})\n",
            " |    inference_output_type: Data type of the output layer. Note that integer\n",
            " |      types (tf.int8 and tf.uint8) are currently only supported for post\n",
            " |      training integer quantization and quantization aware training. (default\n",
            " |      tf.float32, must be in {tf.float32, tf.int8, tf.uint8})\n",
            " |    allow_custom_ops: Boolean indicating whether to allow custom operations.\n",
            " |      When False, any unknown operation is an error. When True, custom ops are\n",
            " |      created for any op that is unknown. The developer needs to provide these\n",
            " |      to the TensorFlow Lite runtime with a custom resolver. (default False)\n",
            " |    experimental_new_converter: Experimental flag, subject to change. Enables\n",
            " |      MLIR-based conversion. (default True)\n",
            " |    experimental_new_quantizer: Experimental flag, subject to change. Enables\n",
            " |      MLIR-based quantization conversion instead of Flatbuffer-based conversion.\n",
            " |      (default True)\n",
            " |    experimental_enable_resource_variables: Experimental flag, subject to\n",
            " |      change. Enables resource variables to be converted by this converter. This\n",
            " |      is only allowed if from_saved_model interface is used. (default False)\n",
            " |  \n",
            " |  Example usage:\n",
            " |  \n",
            " |  ```python\n",
            " |  # Converting a SavedModel to a TensorFlow Lite model.\n",
            " |    converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)\n",
            " |    tflite_model = converter.convert()\n",
            " |  \n",
            " |  # Converting a tf.Keras model to a TensorFlow Lite model.\n",
            " |  converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
            " |  tflite_model = converter.convert()\n",
            " |  \n",
            " |  # Converting ConcreteFunctions to a TensorFlow Lite model.\n",
            " |  converter = tf.lite.TFLiteConverter.from_concrete_functions([func], model)\n",
            " |  tflite_model = converter.convert()\n",
            " |  \n",
            " |  # Converting a Jax model to a TensorFlow Lite model.\n",
            " |  converter = tf.lite.TFLiteConverter.experimental_from_jax([func], [[\n",
            " |      ('input1', input1), ('input2', input2)])\n",
            " |  tflite_model = converter.convert()\n",
            " |  ```\n",
            " |  \n",
            " |  Method resolution order:\n",
            " |      TFLiteConverterV2\n",
            " |      TFLiteFrozenGraphConverterV2\n",
            " |      TFLiteConverterBaseV2\n",
            " |      TFLiteConverterBase\n",
            " |      builtins.object\n",
            " |  \n",
            " |  Methods defined here:\n",
            " |  \n",
            " |  __init__(self, funcs, trackable_obj=None)\n",
            " |      Constructor for TFLiteConverter.\n",
            " |      \n",
            " |      Args:\n",
            " |        funcs: List of TensorFlow ConcreteFunctions. The list should not contain\n",
            " |          duplicate elements.\n",
            " |        trackable_obj: tf.AutoTrackable object associated with `funcs`. A\n",
            " |          reference to this object needs to be maintained so that Variables do not\n",
            " |          get garbage collected since functions have a weak reference to\n",
            " |          Variables. This is only required when the tf.AutoTrackable object is not\n",
            " |          maintained by the user (e.g. `from_saved_model`).\n",
            " |  \n",
            " |  convert(self)\n",
            " |      Converts a TensorFlow GraphDef based on instance variables.\n",
            " |      \n",
            " |      Returns:\n",
            " |        The converted data in serialized format.\n",
            " |      \n",
            " |      Raises:\n",
            " |        ValueError:\n",
            " |          No concrete functions is specified.\n",
            " |          Multiple concrete functions are specified.\n",
            " |          Input shape is not specified.\n",
            " |          Invalid quantization parameters.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Class methods defined here:\n",
            " |  \n",
            " |  experimental_from_jax(serving_funcs, inputs) from builtins.type\n",
            " |      Creates a TFLiteConverter object from a Jax model with its inputs.\n",
            " |      \n",
            " |      Args:\n",
            " |        serving_funcs: A array of Jax functions with all the weights applied\n",
            " |          already.\n",
            " |        inputs: A array of Jax input placeholders tuples list, e.g.,\n",
            " |          jnp.zeros(INPUT_SHAPE). Each tuple list should correspond with the\n",
            " |          serving function.\n",
            " |      \n",
            " |      Returns:\n",
            " |        TFLiteConverter object.\n",
            " |  \n",
            " |  from_concrete_functions(funcs, trackable_obj=None) from builtins.type\n",
            " |      Creates a TFLiteConverter object from ConcreteFunctions.\n",
            " |      \n",
            " |      Args:\n",
            " |        funcs: List of TensorFlow ConcreteFunctions. The list should not contain\n",
            " |          duplicate elements. Currently converter can only convert a single\n",
            " |          ConcreteFunction. Converting multiple functions is under development.\n",
            " |        trackable_obj:   An `AutoTrackable` object (typically `tf.module`)\n",
            " |          associated with `funcs`. A reference to this object needs to be\n",
            " |          maintained so that Variables do not get garbage collected since\n",
            " |          functions have a weak reference to Variables.\n",
            " |      \n",
            " |      Returns:\n",
            " |        TFLiteConverter object.\n",
            " |      \n",
            " |      Raises:\n",
            " |        Invalid input type.\n",
            " |  \n",
            " |  from_keras_model(model) from builtins.type\n",
            " |      Creates a TFLiteConverter object from a Keras model.\n",
            " |      \n",
            " |      Args:\n",
            " |        model: tf.Keras.Model\n",
            " |      \n",
            " |      Returns:\n",
            " |        TFLiteConverter object.\n",
            " |  \n",
            " |  from_saved_model(saved_model_dir, signature_keys=None, tags=None) from builtins.type\n",
            " |      Creates a TFLiteConverter object from a SavedModel directory.\n",
            " |      \n",
            " |      Args:\n",
            " |        saved_model_dir: SavedModel directory to convert.\n",
            " |        signature_keys: List of keys identifying SignatureDef containing inputs\n",
            " |          and outputs. Elements should not be duplicated. By default the\n",
            " |          `signatures` attribute of the MetaGraphdef is used. (default\n",
            " |          saved_model.signatures)\n",
            " |        tags: Set of tags identifying the MetaGraphDef within the SavedModel to\n",
            " |          analyze. All tags in the tag set must be present. (default\n",
            " |          {tf.saved_model.SERVING} or {'serve'})\n",
            " |      \n",
            " |      Returns:\n",
            " |        TFLiteConverter object.\n",
            " |      \n",
            " |      Raises:\n",
            " |        Invalid signature keys.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data descriptors inherited from TFLiteConverterBase:\n",
            " |  \n",
            " |  __dict__\n",
            " |      dictionary for instance variables (if defined)\n",
            " |  \n",
            " |  __weakref__\n",
            " |      list of weak references to the object (if defined)\n",
            "\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Python API \n",
        "Helper code: To identify the installed TensorFlow version, run print(tf.__version__) and to learn more about the TensorFlow Lite converter API, run print(help(tf.lite.TFLiteConverter)).\n",
        "\n",
        "If you've installed TensorFlow 2.x, you have the following two options: (if you've installed TensorFlow 1.x, refer to Github)\n",
        "\n",
        "Convert a TensorFlow 2.x model using tf.lite.TFLiteConverter. A TensorFlow 2.x model is stored using the SavedModel format and is generated either using the high-level tf.keras.* APIs (a Keras model) or the low-level tf.* APIs (from which you generate concrete functions). As a result, you have the following three options (examples are in the next few sections):\n",
        "\n",
        "  tf.lite.TFLiteConverter.from_saved_model() (recommended): Converts a SavedModel.\n",
        "  - `tf.lite.TFLiteConverter.from_keras_model()`: Converts a Keras model.\n",
        "  - `tf.lite.TFLiteConverter.from_concrete_functions()`: Converts concrete functions.\n",
        "\n",
        "Convert a TensorFlow 1.x model using tf.compat.v1.lite.TFLiteConverter (examples are on Github):\n",
        "\n",
        "  - `tf.compat.v1.lite.TFLiteConverter.from_saved_model()`: Converts a SavedModel.\n",
        "  - `tf.compat.v1.lite.TFLiteConverter.from_keras_model_file()`: Converts a Keras model.\n",
        "  - `tf.compat.v1.lite.TFLiteConverter.from_session()`: Converts a GraphDef from a session.\n",
        "  - `tf.compat.v1.lite.TFLiteConverter.from_frozen_graph()`: Converts a Frozen GraphDef from a file. If you have checkpoints, then first convert it to a Frozen GraphDef file and then use this API as shown here."
      ],
      "metadata": {
        "id": "KyTDt90ovVhq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# unzip your model\n",
        "!unzip /content/saved_model.zip -d /content/saved_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Xeqp9m-l8ll",
        "outputId": "cab5a31b-6b27-4264-f8b9-ac3b8b7aba33"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/saved_model.zip\n",
            "   creating: /content/saved_model/content/saved_model/1647401327/\n",
            "   creating: /content/saved_model/content/saved_model/1647401327/assets/\n",
            "  inflating: /content/saved_model/content/saved_model/1647401327/saved_model.pb  \n",
            "  inflating: /content/saved_model/content/saved_model/1647401327/keras_metadata.pb  \n",
            "   creating: /content/saved_model/content/saved_model/1647401327/variables/\n",
            "  inflating: /content/saved_model/content/saved_model/1647401327/variables/variables.index  \n",
            "  inflating: /content/saved_model/content/saved_model/1647401327/variables/variables.data-00000-of-00001  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Convert a SavedModel (recommended)"
      ],
      "metadata": {
        "id": "SuqmRwzDwc1N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the model \n",
        "saved_model_dir = '/content/saved_model/content/saved_model/1647401327'\n",
        "converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "# Save the model\n",
        "with open('model_saved.tflite','wb') as f:\n",
        "  f.write(tflite_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JX3U3K_Lw161",
        "outputId": "2c902f17-91b4-4c3d-dc7f-7fc4491c3a26"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Convert a Keras model"
      ],
      "metadata": {
        "id": "iUAdQG4_wdMY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a model using high-level tf.keras.*APIs\n",
        "model = tf.keras.models.Sequential([\n",
        "                                    tf.keras.layers.Dense(units = 1, input_shape = [1]),\n",
        "                                    tf.keras.layers.Dense(units = 16,activation = 'relu'),\n",
        "                                    tf.keras.layers.Dense(units = 1)\n",
        "])\n",
        "\n",
        "# compile the model\n",
        "model.compile(loss = 'mean_squared_error',\n",
        "              optimizer = 'sgd',\n",
        "              )\n",
        "# train your model\n",
        "model.fit(x = [-1,0,1],y = [-3,-1,1],epochs = 5) # train the model\n",
        "# to generate SavedModel tf.saved_model.save(model,'saved_model_keras_dir')\n",
        "\n",
        "# Convert the model\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "# Save your model\n",
        "with open('model_keras.tflite','wb') as f:\n",
        "  f.write(tflite_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CSLgpzP1zM3a",
        "outputId": "a27d3678-342b-4af9-b685-52b6381df7a3"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1/1 [==============================] - 1s 1s/step - loss: 3.6388\n",
            "Epoch 2/5\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.5429\n",
            "Epoch 3/5\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.4408\n",
            "Epoch 4/5\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.3428\n",
            "Epoch 5/5\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 3.2487\n",
            "INFO:tensorflow:Assets written to: /tmp/tmp28ac4x4u/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmp28ac4x4u/assets\n",
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Convert concrete functions"
      ],
      "metadata": {
        "id": "gjCjYVy9wdVk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a model using low-level tf.*APIs\n",
        "class Squared(tf.Module):\n",
        "  @tf.function(input_signature = [tf.TensorSpec(shape= [None],dtype = tf.float32)])\n",
        "  def __call__(self,x):\n",
        "    return tf.square(x) \n",
        "\n",
        "model = Squared()\n",
        "\n",
        "# (to generate a SavedModel) tf.saved_model_save(model,'saved_model_tf_dir\")\n",
        "concrete_func = model.__call__.get_concrete_function()\n",
        "concrete_func"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wcVQYiOs1bXn",
        "outputId": "69127baf-da63-4c6c-d48a-9ffb830ddef9"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<ConcreteFunction __call__(x) at 0x7F145C1DEB90>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the model\n",
        "# Notes that for the versions earlier than TensorFlow 2.7, the\n",
        "# from_concrete_functions API is able to work when there is only the first\n",
        "# argument given:\n",
        "# > converter = tf.lite.TFLiteConverter.from_concrete_functions([concrete_func])\n",
        "\n",
        "converter = tf.lite.TFLiteConverter.from_concrete_functions([concrete_func],\n",
        "                                                            model\n",
        "                                                            )\n",
        "\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "# Saved the model\n",
        "with open('model_concrete.tflite','wb') as f:\n",
        "  f.write(tflite_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wAklsrgC36c5",
        "outputId": "e5dee5f0-9390-47de-f7be-b0bf7b6d454b"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmp1p_ze_2y/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmp1p_ze_2y/assets\n",
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Command line Tool"
      ],
      "metadata": {
        "id": "TjdKuPZXwdiQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!tflite_convert --help"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lItrS44V4f5m",
        "outputId": "9ca5f366-480b-4295-802d-f88b622f43af"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-03-16 04:00:30.854514: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "usage: tflite_convert [-h] --output_file OUTPUT_FILE\n",
            "                      [--saved_model_dir SAVED_MODEL_DIR | --keras_model_file KERAS_MODEL_FILE]\n",
            "                      [--saved_model_tag_set SAVED_MODEL_TAG_SET]\n",
            "                      [--saved_model_signature_key SAVED_MODEL_SIGNATURE_KEY]\n",
            "                      [--enable_v1_converter]\n",
            "                      [--experimental_new_converter [EXPERIMENTAL_NEW_CONVERTER]]\n",
            "                      [--experimental_new_quantizer [EXPERIMENTAL_NEW_QUANTIZER]]\n",
            "\n",
            "Command line tool to run TensorFlow Lite Converter.\n",
            "\n",
            "optional arguments:\n",
            "  -h, --help            show this help message and exit\n",
            "  --output_file OUTPUT_FILE\n",
            "                        Full filepath of the output file.\n",
            "  --saved_model_dir SAVED_MODEL_DIR\n",
            "                        Full path of the directory containing the SavedModel.\n",
            "  --keras_model_file KERAS_MODEL_FILE\n",
            "                        Full filepath of HDF5 file containing tf.Keras model.\n",
            "  --saved_model_tag_set SAVED_MODEL_TAG_SET\n",
            "                        Comma-separated set of tags identifying the\n",
            "                        MetaGraphDef within the SavedModel to analyze. All\n",
            "                        tags must be present. In order to pass in an empty tag\n",
            "                        set, pass in \"\". (default \"serve\")\n",
            "  --saved_model_signature_key SAVED_MODEL_SIGNATURE_KEY\n",
            "                        Key identifying the SignatureDef containing inputs and\n",
            "                        outputs. (default DEFAULT_SERVING_SIGNATURE_DEF_KEY)\n",
            "  --enable_v1_converter\n",
            "                        Enables the TensorFlow V1 converter in 2.0\n",
            "  --experimental_new_converter [EXPERIMENTAL_NEW_CONVERTER]\n",
            "                        Experimental flag, subject to change. Enables MLIR-\n",
            "                        based conversion instead of TOCO conversion. (default\n",
            "                        True)\n",
            "  --experimental_new_quantizer [EXPERIMENTAL_NEW_QUANTIZER]\n",
            "                        Experimental flag, subject to change. Enables MLIR-\n",
            "                        based quantizer instead of flatbuffer conversion.\n",
            "                        (default True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# convert SavedModel\n",
        "!tflite_convert \\\n",
        "--saved_model_dir= /content/saved_model/content/saved_model/1647401327 \\\n",
        "--output_file =/content/model_saved2.tflite"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s_tYXskt4jl7",
        "outputId": "52a696fb-a07b-450f-a523-f003bd232abe"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-03-16 04:07:25.037898: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "usage: tflite_convert [-h] --output_file OUTPUT_FILE\n",
            "                      [--saved_model_dir SAVED_MODEL_DIR | --keras_model_file KERAS_MODEL_FILE]\n",
            "                      [--saved_model_tag_set SAVED_MODEL_TAG_SET]\n",
            "                      [--saved_model_signature_key SAVED_MODEL_SIGNATURE_KEY]\n",
            "                      [--enable_v1_converter]\n",
            "                      [--experimental_new_converter [EXPERIMENTAL_NEW_CONVERTER]]\n",
            "                      [--experimental_new_quantizer [EXPERIMENTAL_NEW_QUANTIZER]]\n",
            "tflite_convert: error: one of the arguments --saved_model_dir --keras_model_file is required\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert\n",
        "tflite_convert \\\n",
        "  --keras_model_file=/tmp/mobilenet_keras_model.h5 \\\n",
        "  --output_file=/tmp/mobilenet.tflite"
      ],
      "metadata": {
        "id": "k6QddvjC4-Mq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}