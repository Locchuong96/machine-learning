{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8dfc0243",
   "metadata": {},
   "source": [
    "## Word embeddings\n",
    "\n",
    "Embedding Projector: http://projector.tensorflow.org/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9d81d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io \n",
    "import os\n",
    "import re\n",
    "import shutil\n",
    "import string\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d0ebaec",
   "metadata": {},
   "source": [
    "## Representing text as numbers\n",
    "Machine learning models take vectors (arrays of numbers) as input. When working with text, the first thing you must do is come up with a strategy to convert strings to numbers (or to \"vectorize\" the text) before feeding it to the model. In this section, you will look at three strategies for doing so.\n",
    "\n",
    "### One-hot encodings:\n",
    "\n",
    "As a first idea, you might \"one-hot\" encode each word in your vocabulary. Consider the sentence \"The cat sat on the mat\". The vocabulary (or unique words) in this sentence is (cat, mat, on, sat, the). To represent each word, you will create a zero vector with length equal to the vocabulary, then place a one in the index that corresponds to the word. This approach is shown in the following diagram.\n",
    "\n",
    "![one-hot](./one-hot.png)\n",
    "\n",
    "To create a vector that contains the encoding of the sentence, you could then concatenate the one-hot vectors for each word.\n",
    "\n",
    "### Encode each word with a unique number:\n",
    "\n",
    "A second approach you might try is to encode each word using a unique number. Continuing the example above, you could assign 1 to \"cat\", 2 to \"mat\", and so on. You could then encode the sentence \"The cat sat on the mat\" as a dense vector like [5, 1, 4, 3, 5, 2]. This approach is efficient. Instead of a sparse vector, you now have a dense one (where all elements are full).\n",
    "\n",
    "There are two downsides to this approach, however:\n",
    "\n",
    "- The integer-encoding is arbitrary (it does not capture any relationship between words).\n",
    "\n",
    "- An integer-encoding can be challenging for a model to interpret. A linear classifier, for example, learns a single weight for each feature. Because there is no relationship between the similarity of any two words and the similarity of their encodings, this feature-weight combination is not meaningful.\n",
    "\n",
    "### Word embeddings:\n",
    "\n",
    "Word embeddings give us a way to use an efficient, dense representation in which similar words have a similar encoding. Importantly, you do not have to specify this encoding by hand. An embedding is a dense vector of floating point values (the length of the vector is a parameter you specify). Instead of specifying the values for the embedding manually, they are trainable parameters (weights learned by the model during training, in the same way a model learns weights for a dense layer). It is common to see word embeddings that are 8-dimensional (for small datasets), up to 1024-dimensions when working with large datasets. A higher dimensional embedding can capture fine-grained relationships between words, but takes more data to learn.\n",
    "\n",
    "![embedding2](./embedding2.png)\n",
    "\n",
    "Above is a diagram for a word embedding. Each word is represented as a 4-dimensional vector of floating point values. Another way to think of an embedding is as \"lookup table\". After these weights have been learned, you can encode each word by looking up the dense vector it corresponds to in the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e15631cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_array: (32, 10)\n",
      "output_array: (32, 10, 64)\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Embedding(input_dim = 1000,output_dim = 64,input_length = 10))\n",
    "'''\n",
    "The model will take as input an iterger matrix of size (batch,input_length),and the largest integer (i.e word index)\n",
    "in the input. should be no larger than 999 (vocabulary size).\n",
    "Now model.output_shape is (None,10,64), where `None` is the batch dimension\n",
    "input_dim : Integer, size of vocabulary, i.e maximum is interger index +1 \n",
    "output_dim : Integer, Dimension of dense embedding\n",
    "input_length: Length of input sequences, when it is constant. This argument is required i\n",
    "f you are going to connect Flatten then Dense layers upstream (without it, the shape of the dense outputs cannot be computed).\n",
    "\n",
    "'''\n",
    "input_array = np.random.randint(1000,size = (32,10)) # (sample_number,input_length)\n",
    "print(f\"input_array: {input_array.shape}\")\n",
    "model.compile('rmsprop','mse')\n",
    "output_array = model.predict(input_array)\n",
    "print(f\"output_array: {output_array.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e5e50b",
   "metadata": {},
   "source": [
    "## Download the IMDb Dataset\n",
    "\n",
    "You will use the [Large Movie Review](http://ai.stanford.edu/~amaas/data/sentiment/) Dataset through the tutorial. You will train a sentiment classifier model on this dataset and in the process learn embeddings from scratch. To read more about loading a dataset from scratch, see the [Loading text tutorial](https://www.tensorflow.org/tutorials/load_data/text).\n",
    "\n",
    "Download the dataset using Keras file utility and take a look at the directories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be3f2301",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
      "84131840/84125825 [==============================] - 606s 7us/step\n",
      "84140032/84125825 [==============================] - 606s 7us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['imdb.vocab', 'imdbEr.txt', 'README', 'test', 'train']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\"\n",
    "\n",
    "dataset = tf.keras.utils.get_file(\"aclImdb_v1.tar.gz\",\n",
    "                                  url,\n",
    "                                  untar = True,\n",
    "                                  cache_dir = '.',\n",
    "                                  cache_subdir = ''\n",
    "                                 )\n",
    "\n",
    "dataset_dir = os.path.join(os.path.dirname(dataset),'aclImdb')\n",
    "os.listdir(dataset_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c34cc0f",
   "metadata": {},
   "source": [
    "Take a look at the `train/` directory. It has `pos` and `neg` folders with movie reviews labelled as positive and negative respectively. You will use reviews from `pos` and `neg` folders to train a binary classification model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a08197d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['labeledBow.feat',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'unsupBow.feat',\n",
       " 'urls_neg.txt',\n",
       " 'urls_pos.txt',\n",
       " 'urls_unsup.txt']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dir = os.path.join(dataset_dir,'train')\n",
    "os.listdir(train_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c3b3c8",
   "metadata": {},
   "source": [
    "The `train` directory also has additional folders which should be removed before creating training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9318ce45",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_dir = os.path.join(train_dir,'unsup')\n",
    "shutil.rmtree(remove_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c05dcc58",
   "metadata": {},
   "source": [
    "Next, create a `tf.data.Dataset` using `tf.keras.utils.text_dataset_from_directory`. You can read more about using this utility in this [text classification tutorial](https://www.tensorflow.org/tutorials/keras/text_classification).\n",
    "\n",
    "Use the train directory to create both train and validation datasets with a split of 20% for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "327df91b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25000 files belonging to 2 classes.\n",
      "Using 20000 files for training.\n",
      "Found 25000 files belonging to 2 classes.\n",
      "Using 5000 files for validation.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 1024\n",
    "seed = 123\n",
    "# train\n",
    "train_ds = tf.keras.utils.text_dataset_from_directory('aclImdb/train',\n",
    "                                                       batch_size = batch_size,\n",
    "                                                       validation_split = 0.2,\n",
    "                                                       subset = 'training',\n",
    "                                                       seed = seed\n",
    "                                                        )\n",
    "\n",
    "val_ds = tf.keras.utils.text_dataset_from_directory('aclImdb/test',\n",
    "                                                       batch_size = batch_size,\n",
    "                                                       validation_split = 0.2,\n",
    "                                                       subset = 'validation',\n",
    "                                                       seed = seed\n",
    "                                                        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136438fe",
   "metadata": {},
   "source": [
    "Take a look at a few movie reviews and their labels `(1: positive, 0: negative)` from the train dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a5631053",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  :  b\"Wow. Some movies just leave me speechless. This was undeniably one of those movies. When I left the theatre, not a single word came to my mouth. All I had was an incredible urge to slam my head against the theatre wall to help me forget about the last hour and a half. Unfortunately, it didn't work. Honestly, this movie has nothing to recommend. The humor was at the first grade level, at best, the acting was overly silly, and the plot was astronomically far-fetched. I hearby pledge never to see an other movie starring Chris Kattan or any other cast-member of SNL.\"\n",
      "\n",
      "\n",
      "1  :  b'If any show in the last ten years deserves a 10, it is this rare gem. It allows us to escape back to a time when things were simpler and more fun. Filled with heart and laughs, this show keeps you laughing through the three decades of difference. The furniture was ugly, the clothes were colorful, and the even the drugs were tolerable. The hair was feathered, the music was accompanied by roller-skates, and in the words of Merle Haggard, \"a joint was a bad place to be\". Take a trip back to the greatest time in American history. Fall in love with characters and the feel good essence of the small town where people were nicer to each other. This classic is on television as much as \"Full House\". Don\\'t miss it, and always remember to \"Shake your groove thing!!!\"'\n",
      "\n",
      "\n",
      "1  :  b'Clearly an hilarious movie.<br /><br />It angers me to see the poor ratings given to this piece of comic genius<br /><br />Please look at this for what it is, a funny, ridiculous enjoyable film. Laugh for christ sake!<br /><br />'\n",
      "\n",
      "\n",
      "0  :  b\"Distasteful, cliched thriller has young couple doing cross-country research on America's most infamous murder sites, becoming road partners with a dim-witted young woman and her snarling boyfriend--who is an actual psycho. Arty and alienating, the film's tone alternates between pouty pseudo-irony and silly flamboyance. Handsomely-made perhaps, but ultimately laughable. Brad Pitt's performance as the low-rent killer is godawful. * from ****\"\n",
      "\n",
      "\n",
      "1  :  b\"Scott is right. The best 2 person sword duel ever put on film is in the middle of this movie. The sword fights with multiple fighters are not the best although quite good. However, the fight in the middle is the best even compared to Japanese samurai movies. Chinese swordplay scenes in my opinion have never surpassed the Japanese in terms of entertainment value. Especially in scenes where one guy must battle a group of enemies, Japanese movies excel, example being the Lone Wolf and Cub series. Even though duels in Japanese cinema last only seconds or a minute at the most, the sheer intensity of those moments made them better. But, this is one example where Chinese swordplay surpasses the Japanese. The scene in the middle of this film was a five minute long fight with the most amazing choreography ever. The other fights in this movie are good too but even if they sucked this movie would get a 7 for that one scene. If you haven't seen it, you have to. John Woo is the man.\"\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for text_batch,label_batch in train_ds.take(1):\n",
    "    for i in range(5):\n",
    "        print(label_batch[i].numpy(),\" : \",text_batch.numpy()[i])\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d65f6c8",
   "metadata": {},
   "source": [
    "## Configure the dataset for performance\n",
    "These are two important methods you should use when loading data to make sure that I/O does not become blocking.\n",
    "\n",
    ".cache() keeps data in memory after it's loaded off disk. This will ensure the dataset does not become a bottleneck while training your model. If your dataset is too large to fit into memory, you can also use this method to create a performant on-disk cache, which is more efficient to read than many small files.\n",
    "\n",
    ".prefetch() overlaps data preprocessing and model execution while training.\n",
    "\n",
    "You can learn more about both methods, as well as how to cache data to disk in the [data performance guide](https://www.tensorflow.org/guide/data_performance)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1b1ee93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = train_ds.cache().prefetch(buffer_size = tf.data.AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size = tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "522c1473",
   "metadata": {},
   "source": [
    "## Using the Embedding layer\n",
    "\n",
    "Keras makes it easy to use word embeddings. Take a look at the [Embedding](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Embedding) layer.\n",
    "\n",
    "The Embedding layer can be understood as a lookup table that maps from integer indices (which stand for specific words) to dense vectors (their embeddings). The dimensionality (or width) of the embedding is a parameter you can experiment with to see what works well for your problem, much in the same way you would experiment with the number of neurons in a Dense layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b07006d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embed a 1000 word vocabulary into 5 dimensions\n",
    "embedding_layer = tf.keras.layers.Embedding(1000,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b5f0dcf",
   "metadata": {},
   "source": [
    "When you create an Embedding layer, the weights for the embedding are randomly initialized (just like any other layer). During training, they are gradually adjusted via backpropagation. Once trained, the learned word embeddings will roughly encode similarities between words (as they were learned for the specific problem your model is trained on).\n",
    "\n",
    "If you pass an integer to an embedding layer, the result replaces each integer with the vector from the embedding table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "628a663d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 5)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.03370622, -0.04908353, -0.0200971 , -0.0451408 , -0.01668329],\n",
       "       [ 0.01682807, -0.01845165, -0.01166041, -0.00564532,  0.04736647],\n",
       "       [ 0.02346439, -0.04127623, -0.00068667,  0.04478325, -0.00877509]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# width = np.random.randint(10)\n",
    "# input = np.random.rand(width)\n",
    "result = embedding_layer(tf.constant([1,2,3]))\n",
    "print(result.shape)\n",
    "result.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "044835b5",
   "metadata": {},
   "source": [
    "For text or sequence problems, the Embedding layer takes a 2D tensor of integers, of shape `(samples, sequence_length)`, where each entry is a sequence of integers. It can embed sequences of variable lengths. You could feed into the embedding layer above batches with shapes `(32, 10)` (batch of 32 sequences of length 10) or `(64, 15)` (batch of 64 sequences of length 15).\n",
    "\n",
    "The returned tensor has one more axis than the input, the embedding vectors are aligned along the new last axis. Pass it a `(2, 3)` input batch and the output is `(2, 3, N)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7752fd4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 3, 5)\n",
      "tf.Tensor(\n",
      "[[[-0.02427975  0.01467308  0.00526615 -0.00207376  0.00761747]\n",
      "  [ 0.03370622 -0.04908353 -0.0200971  -0.0451408  -0.01668329]\n",
      "  [ 0.01682807 -0.01845165 -0.01166041 -0.00564532  0.04736647]]\n",
      "\n",
      " [[ 0.02346439 -0.04127623 -0.00068667  0.04478325 -0.00877509]\n",
      "  [ 0.04794813 -0.00600418  0.03465143 -0.03749007 -0.04010221]\n",
      "  [-0.01621849 -0.02563468 -0.03893682 -0.00997553 -0.03375311]]], shape=(2, 3, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "result = embedding_layer(tf.constant([[0,1,2],[3,4,5]]))\n",
    "print(result.shape)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "271806bb",
   "metadata": {},
   "source": [
    "When given a batch of sequences as input, an embedding layer returns a 3D floating point tensor, of shape `(samples, sequence_length, embedding_dimensionality)`. To convert from this sequence of variable length to a fixed representation there are a variety of standard approaches. You could use an RNN, Attention, or pooling layer before passing it to a Dense layer. This tutorial uses pooling because it's the simplest. [The Text Classification with an RNN tutorial](https://www.tensorflow.org/text/tutorials/text_classification_rnn) is a good next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "cd53f865",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[b\"If you want an undemanding and reasonably amusing hour or so, then it's OK to watch this. It's not all that bad, really. Yeah, it's got more lapses in logic than I care to describe here and might tax the patience of people - like myself, I have to admit - who are inclined to throw things at the TV on occasion, but it's funny at least. Just because it's not always INTENTIONALLY funny, there's no need to let that get you down.<br /><br />However, if you've read the book - or any of the other books by Brookmyre - then you'd probably best avoid it. I've read them all and when I first watched this film, I despised it. I've trashed it in detail and at great length on another site, in fact. The TV plot bears practically no relevance at all to that of the book and served only to outrage and infuriate many faithful (and admittedly rabid) Brookmyre fans.<br /><br />Best bit of advice..? Watch this, then read the book and only THEN make your comparisons and submit your judgement.\"\n",
      " b\"Dressed to Kill starts off with Kate Miller (Angie Dickinson) having a sexually explicit nightmare, later on that day she visits her psychiatrist Dr. Robert Elliott (Michael Caine) for a session in which she admits to be sexually frustrated & unfulfilled in her current marriage. Kate then visits a museum & picks up a stranger, they go back to his apartment for casual sex, when done Kate is set to leave but is attacked & killed in the buildings elevator by a razor blade wielding blonde woman. Prostitute Liz Blake (Nancy Allen) discovers the gruesome scene & sees the killer but manages to escape. Detective Marino (Dennis Franz) says he suspects Liz as being the killer as there are no other witnesses so Liz teams up with Kate's son Peter (Keith Gordon) to track down the real killer, clear Liz's name & see that justice is done...<br /><br />Written & directed by Brian De Palma I thought Dressed to Kill was a good solid psychological murder mystery. The script is measured & slow at times but it likes to focus on the character's so you really know them, the entire first twenty minutes is just developing Kate as a character before she is suddenly killed off, then the film switches it's attentions to Liz & no one else gets a look in. This way Dressed to Kill is quite absorbing & engaging, unfortunately the character's themselves aren't exactly likable. I found some of the dialogue quite funny at times, especially the dirty talk that Liz spouts occasionally. The killers motives are somewhat plausible but I guess you'd have to be pretty messed up to do anything suggested in Dressed to Kill. It's a good film but it didn't excite me that much & I didn't really find any character to root for or like. The film tacks on a needless & unnecessary twist ending that I didn't really see the point of.<br /><br />Director De Palma directs with style & visual flair, from the art museum sequence to a car chase & as a whole it's impeccably filmed throughout. I'd imagine that every shot in Dressed to Kill had a great deal of thought put into it. I felt the film was a bit flat & uninspired at times though, nothing about it really excited me that much. There is a fair bit of nudity, some sex & rape along with a few bits of gore & violence, Kate's murder by razor blade in the elevator being the highlight, if that's the right word. However, it's by no means as shocking or controversial when viewed today as many would have you believe.<br /><br />With a supposed budget of about $6,500,000 Dressed to Kill has that glossy high production value feel of a Hollywood film. The New York locations are nice, the cinematography is good & as a whole it's extremely well made. I thought the music was inappropriate & was far to loud & intrusive. The acting is OK but despite his top billing I didn't think Caine had that much screen time. Allen was married to director De Palma at the time Dressed to Kill was made, interestingly out of the four films she appeared in made by De Palma in two of them, this & Blow Out (1981), he cast her as a prostitute... A body double was used for Dickinson as she pleasures herself in a shower at the start.<br /><br />Dressed to Kill is a good thriller that is well worth watching but I didn't think it quite lived up to it's lofty reputation. Good but not brilliant.\"\n",
      " b\"I usually enjoy Loretta Young's early movies: her acting back then was light and breezy, and she sure knew how to wear clothes. But this one is just a loser from the word go except for a funny supporting turn by Glenda Farrell. Young is a hatcheck girl who talks her writer-husband (Paul Lukas) into becoming a championship bridge player. It's not the most cinematic of games, and the long, talky middle part in which their marriage falls apart just about kills the film.<br /><br />There's one interesting bit though. As Lukas and Ferdinand Gottschalk start their climactic game, a series of quick shots show airplanes, trains, football games, even a diver in mid-air, freezing in anticipation of the event. It's the earliest use of a freeze frame I've seen in an American film. Wish the rest of it were that inventive-and funny.\"\n",
      " ...\n",
      " b\"Nobody said movies had to be realistic did they? I really liked this movie because I remember when I first saw it in junior high. For all the kids who remember the PMRC and albums before there were warning stickers, it's a cool story for all those kids who were part of the mid to late 80's headbanger crowd.\"\n",
      " b'There were some great moments of reality in there depicting modern day life (not only in Japan, but everywhere). It shows how stifling ones culture can be, and wanting to break out of the mold its created for you.<br /><br />The dancing was just a vehicle for saying \"do what you love even if its against the norm\". Rather Billy Elliot like I would say. I enjoyed that film as well. <br /><br />The humour was well timed, and the touching moments felt so real, you could feel the awkwardness between Sugiyama and his wife, the tantrums in the dance hall. I loved Aoki - him and that wig and his excessiveness on the dance floor made me simply howl!<br /><br />The actors all did a wonderful job, the story was well written. I watched it a second time and caught some little nuances that I missed on the first viewing. Good entertainment!'\n",
      " b'After watching this on the MST3K episode, I have to wonder how many movies this film borrows from. It seems to combine elements of Logans Run, Farenheight 451, Final Sacrifice and at least several others. At one point I was really expecting Cris Makepease to call Lee Majors ROWSDOWER. <br /><br />I wonder if the director has any clue how many holes there are in the plot. like the fact that, even though gas is unavailable, there is plenty of it in abandoned gas stations, and the stations are located close enough together to keep an F1 race car going all the way across the country.'], shape=(1024,), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "# Create a custom standardization function to strip HTML break tags '<br />'\n",
    "def custom_standardization(input_data):\n",
    "    lowercase = tf.string.lower(input_data)\n",
    "    stripped_html = tf.string.regex_replace(lowercase, '<br />',' ')\n",
    "    return tf.strings.regex_replace(stripped_html,'[%s]' % re.escape(string.punctuation),'')\n",
    "\n",
    "# Vocabulary size and number of words in a sequence\n",
    "vocab_size = 10000\n",
    "sequence_length = 100\n",
    "\n",
    "text_ds = train_ds.map(lambda x,y:x)\n",
    "for i in text_ds.take(1):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "39691908",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of data (1024,)\n",
      "237551\n",
      "b'If'\n"
     ]
    }
   ],
   "source": [
    "vocab_data = []\n",
    "print(f\"shape of data {i.shape}\")\n",
    "for j in range(i.shape[0]):\n",
    "    vocab_data += i.numpy()[j].split()\n",
    "print(len(vocab_data))\n",
    "print(vocab_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "cbfb18f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_data_str = [x.decode('utf-8') for x in vocab_data]\n",
    "vocab_data_decode = []\n",
    "for  text in vocab_data_str:\n",
    "    if text not in vocab_data_decode:\n",
    "        vocab_data_decode.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "125a6b01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35108"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab_data_decode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "e3238c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Use the text vectorization layer to normalize, split, and map strings to integers\n",
    "Note that the layer uses the custom standardization defined above,\n",
    "Set maximum_sequence length as all samples are not of the same length\n",
    "'''\n",
    "vectorize_layer = tf.keras.layers.TextVectorization(#standardize=custom_standardization,\n",
    "                                                    max_tokens=len(vocab_data_decode)+2, # Passed vocab size is 35960, max vocab size is 35958?\n",
    "                                                    output_mode='int',\n",
    "                                                    output_sequence_length=sequence_length,\n",
    "                                                    vocabulary = vocab_data_decode                                                       \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d688338e",
   "metadata": {},
   "source": [
    "## TextVectorization\n",
    "\n",
    "    \n",
    "    tf.keras.layers.TextVectorization(\n",
    "        max_tokens=None,\n",
    "        standardize='lower_and_strip_punctuation',\n",
    "        split='whitespace',\n",
    "        ngrams=None,\n",
    "        output_mode='int',\n",
    "        output_sequence_length=None,\n",
    "        pad_to_max_tokens=False,\n",
    "        vocabulary=None,\n",
    "        idf_weights=None,\n",
    "        sparse=False,\n",
    "        ragged=False,\n",
    "        **kwargs\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9df2ea06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 1, 4, 0],\n",
       "       [1, 4, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_dataset = tf.data.Dataset.from_tensor_slices(['foo','bar','baz'])\n",
    "# Create the layer\n",
    "vectorize_layer = tf.keras.layers.TextVectorization(\n",
    "max_tokens = max_features,\n",
    "output_mode  = 'int',\n",
    "output_sequence_length = max_len\n",
    ")\n",
    "'''\n",
    "Now that the vocab layer has been created, call adapt on the text-only dataset to create the vocabulary,\n",
    "You don't have to batch, but for large datasets this mean are keeping spare copies of the dataset.\n",
    "'''\n",
    "vectorize_layer.adapt(text_dataset.batch(64))\n",
    "# Create the model that uses the vectorize text layer\n",
    "model = tf.keras.models.Sequential()\n",
    "'''\n",
    "Start by creating an explicit input layer, it needs to have a shape of (1,), because we need to guarantee that there is \n",
    "exactly one string input per batch and the dtype needs to be string\n",
    "'''\n",
    "model.add(tf.keras.Input(shape = (1,),dtype = tf.string))\n",
    "'''\n",
    "The first layer in our model is vectorization layer, After this layer, we have a tensor of shape (batch_size, max_len) containing\n",
    "vocab indices\n",
    "'''\n",
    "model.add(vectorize_layer)\n",
    "'''\n",
    "Now let the model can map string to intergers, and you can add an embedding layer to map these integers to learned embeddings\n",
    "'''\n",
    "input_data =[['foo qux bar'],['qux bar']]\n",
    "model.predict(input_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "bbe18702",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', '[UNK]', 'earth', 'wind', 'and', 'fire']"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "This example instantiates TextVectorization layer by passing a list of vocabulary term to layer method\n",
    "'''\n",
    "vocab_data = ['earth','wind','and','fire']\n",
    "max_features = 5000 # Maximum vocab size\n",
    "max_len = 4 # Sequence length to pad the output to\n",
    "'''\n",
    "Create the layer, passing the vocab directly, You can also pass the vocabulary arg a path to a file containing one vocabulary word per line\n",
    "'''\n",
    "vectorize_layer = tf.keras.layers.TextVectorization(max_tokens = max_features,\n",
    "                                                    output_mode = 'int',\n",
    "                                                    output_sequence_length = max_len,\n",
    "                                                    vocabulary = vocab_data\n",
    ")\n",
    "'''\n",
    "Because we are passed the vocabulary directly, we dont need to adapt the layer - the vocabulary is already set,\n",
    "The vocabulary contains the padding token ('') and OOV token (['UNK']) as well as  the passed tokens\n",
    "'''\n",
    "vectorize_layer.get_vocabulary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d2a02d6",
   "metadata": {},
   "source": [
    "## Create a classification model\n",
    "Use the Keras Sequential API to define the sentiment classification model. In this case it is a \"Continuous bag of words\" style model.\n",
    "\n",
    "- The TextVectorization layer transforms strings into vocabulary indices. You have already initialized vectorize_layer as a TextVectorization layer and built its vocabulary by calling adapt on text_ds. Now vectorize_layer can be used as the first layer of your end-to-end classification model, feeding transformed strings into the Embedding layer.\n",
    "\n",
    "- The Embedding layer takes the integer-encoded vocabulary and looks up the embedding vector for each word-index. These vectors are learned as the model trains. The vectors add a dimension to the output array. The resulting dimensions are: (batch, sequence, embedding).\n",
    "\n",
    "- The GlobalAveragePooling1D layer returns a fixed-length output vector for each example by averaging over the sequence dimension. This allows the model to handle input of variable length, in the simplest way possible.\n",
    "\n",
    "- The fixed-length output vector is piped through a fully-connected (Dense) layer with 16 hidden units.\n",
    "\n",
    "- The last layer is densely connected with a single output node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "5326315b",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 16\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    vectorize_layer,\n",
    "    tf.keras.layers.Embedding(len(vocab_data_decode)+2,embedding_dim,name = 'embedding'),\n",
    "    tf.keras.layers.AveragePooling1D(),\n",
    "    tf.keras.layers.Dense(16,activation = 'relu'),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "aaf1b080",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'adam',\n",
    "             loss = tf.keras.losses.BinaryCrossentropy(),\n",
    "             metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "cb9f3998",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tensorboard callback\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir = 'logs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "ea8b27ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "20/20 [==============================] - 96s 5s/step - loss: 1.6066 - accuracy: 0.5028 - val_loss: 1.3084 - val_accuracy: 0.4886\n",
      "Epoch 2/15\n",
      "20/20 [==============================] - 7s 353ms/step - loss: 1.2004 - accuracy: 0.5028 - val_loss: 1.1573 - val_accuracy: 0.4886\n",
      "Epoch 3/15\n",
      "20/20 [==============================] - 7s 354ms/step - loss: 1.0828 - accuracy: 0.5028 - val_loss: 1.0573 - val_accuracy: 0.4886\n",
      "Epoch 4/15\n",
      "20/20 [==============================] - 7s 365ms/step - loss: 0.9950 - accuracy: 0.5028 - val_loss: 0.9752 - val_accuracy: 0.4886\n",
      "Epoch 5/15\n",
      "20/20 [==============================] - 7s 362ms/step - loss: 0.9218 - accuracy: 0.5028 - val_loss: 0.9059 - val_accuracy: 0.4886\n",
      "Epoch 6/15\n",
      "20/20 [==============================] - 7s 368ms/step - loss: 0.8606 - accuracy: 0.5028 - val_loss: 0.8486 - val_accuracy: 0.4886\n",
      "Epoch 7/15\n",
      "20/20 [==============================] - 7s 358ms/step - loss: 0.8107 - accuracy: 0.5028 - val_loss: 0.8025 - val_accuracy: 0.4886\n",
      "Epoch 8/15\n",
      "20/20 [==============================] - 7s 363ms/step - loss: 0.7714 - accuracy: 0.5060 - val_loss: 0.7673 - val_accuracy: 0.4939\n",
      "Epoch 9/15\n",
      "20/20 [==============================] - 7s 374ms/step - loss: 0.7420 - accuracy: 0.5075 - val_loss: 0.7419 - val_accuracy: 0.4952\n",
      "Epoch 10/15\n",
      "20/20 [==============================] - 7s 342ms/step - loss: 0.7211 - accuracy: 0.5102 - val_loss: 0.7241 - val_accuracy: 0.4996\n",
      "Epoch 11/15\n",
      "20/20 [==============================] - 7s 366ms/step - loss: 0.7065 - accuracy: 0.5156 - val_loss: 0.7121 - val_accuracy: 0.5069\n",
      "Epoch 12/15\n",
      "20/20 [==============================] - 7s 372ms/step - loss: 0.6967 - accuracy: 0.5240 - val_loss: 0.7043 - val_accuracy: 0.5173\n",
      "Epoch 13/15\n",
      "20/20 [==============================] - 7s 344ms/step - loss: 0.6900 - accuracy: 0.5339 - val_loss: 0.6992 - val_accuracy: 0.5278\n",
      "Epoch 14/15\n",
      "20/20 [==============================] - 7s 339ms/step - loss: 0.6854 - accuracy: 0.5416 - val_loss: 0.6958 - val_accuracy: 0.5347\n",
      "Epoch 15/15\n",
      "20/20 [==============================] - 7s 340ms/step - loss: 0.6820 - accuracy: 0.5470 - val_loss: 0.6935 - val_accuracy: 0.5388\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_ds,\n",
    "         validation_data = val_ds,\n",
    "         epochs = 15,\n",
    "         callbacks = [tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "7f407e54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "text_vectorization_37 (TextV (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 100, 16)           561760    \n",
      "_________________________________________________________________\n",
      "average_pooling1d_1 (Average (None, 50, 16)            0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 50, 16)            272       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 50, 1)             17        \n",
      "=================================================================\n",
      "Total params: 562,049\n",
      "Trainable params: 562,049\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# summary your model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823101df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View tensorboard callback on google colab\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "6d8cdd37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import helper_functions as hp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "2279d4f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "hp.plot_loss_curves(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f8a350",
   "metadata": {},
   "source": [
    "## Retrieve the trained word embeddings and save them to disk\n",
    "Next, retrieve the word embeddings learned during training. The embeddings are weights of the Embedding layer in the model. The weights matrix is of shape `(vocab_size, embedding_dimension)`.\n",
    "\n",
    "Obtain the weights from the model using `get_layer()` and `get_weights()`. The get_vocabulary() function provides the vocabulary to build a metadata file with one token per line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "c0f473d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = model.get_layer('embedding').get_weights()[0]\n",
    "vocab = vectorize_layer.get_vocabulary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "340b5a67",
   "metadata": {},
   "source": [
    "Write the weights to disk. To use the Embedding Projector, you will upload two files in tab separated format: a file of vectors (containing the embedding), and a file of meta data (containing the words)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "e1891d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_v = io.open('vectors.tsv','w',encoding = 'utf-8')\n",
    "out_m = io.open('metadata.tsv','w',encoding = 'utf-8')\n",
    "for index,word in enumerate(vocab):\n",
    "    if index == 0:\n",
    "        continue # skip 0, it's padding\n",
    "    vec = weights[index]\n",
    "    out_v.write('\\t'.join([str(x) for x in vec]) + \"\\n\")\n",
    "    out_m.write(word + '\\n')\n",
    "out_v.close()\n",
    "out_m.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce5113c",
   "metadata": {},
   "source": [
    "## Visualize the embeddings\n",
    "To visualize the embeddings, upload them to the embedding projector.\n",
    "\n",
    "Open the Embedding Projector (this can also run in a local TensorBoard instance).\n",
    "\n",
    "Click on \"Load data\".\n",
    "\n",
    "Upload the two files you created above: vecs.tsv and meta.tsv.\n",
    "\n",
    "The embeddings you have trained will now be displayed. You can search for words to find their closest neighbors. For example, try searching for \"beautiful\". You may see neighbors like \"wonderful\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f3d1c71",
   "metadata": {},
   "source": [
    "## Reference\n",
    "\n",
    "https://www.tensorflow.org/api_docs/python/tf/keras/layers/TextVectorization\n",
    "\n",
    "https://www.tensorflow.org/api_docs/python/tf/keras/layers/Embedding\n",
    "\n",
    "https://www.tensorflow.org/tutorials/load_data/text\n",
    "\n",
    "https://www.tensorflow.org/tutorials/keras/text_classification\n",
    "\n",
    "https://www.tensorflow.org/text/tutorials/text_classification_rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6a0105",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
